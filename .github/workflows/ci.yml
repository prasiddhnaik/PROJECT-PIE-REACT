name: ðŸš€ AI Portfolio Calculator - CI/CD Pipeline

# Comprehensive continuous integration and deployment workflow
# Professional-grade automation for code quality, testing, and deployment

on:
  push:
    branches: [ main, develop, release/* ]
  pull_request:
    branches: [ main, develop ]
  release:
    types: [ published ]
  schedule:
    # Run nightly builds at 2 AM UTC
    - cron: '0 2 * * *'

# Environment variables
env:
  PYTHON_VERSION: '3.9'
  NODE_VERSION: '18'
  STREAMLIT_ENV: 'test'
  TESTING: 'true'

# Permissions for security
permissions:
  contents: read
  security-events: write
  actions: read
  checks: write
  pull-requests: write

jobs:
  # ==========================================
  # ðŸ§ª TESTING & QUALITY ASSURANCE
  # ==========================================
  
  test:
    name: ðŸ§ª Test Suite
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ['3.9', '3.10', '3.11', '3.12']
    
    steps:
    - name: ðŸ“¥ Checkout Code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Full history for better analysis
    
    - name: ðŸ Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
        cache: 'pip'
    
    - name: ðŸ“¦ Install Dependencies
      run: |
        python -m pip install --upgrade pip setuptools wheel
        pip install -r requirements.txt
        pip install pytest pytest-cov pytest-xdist pytest-mock coverage[toml]
    
    - name: ðŸ” Verify Installation
      run: |
        python -c "import streamlit, plotly, pandas, numpy; print('âœ… Core dependencies OK')"
        python -c "import portfolio_return_calculator; print('âœ… Application modules OK')"
    
    - name: ðŸ§ª Run Test Suite
      run: |
        pytest \
          --cov=portfolio_return_calculator \
          --cov=streamlit_portfolio_app \
          --cov-report=xml \
          --cov-report=html \
          --cov-report=term-missing \
          --junitxml=test-results.xml \
          --tb=short \
          -v
    
    - name: ðŸ“Š Upload Coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella
        fail_ci_if_error: false
    
    - name: ðŸ“‹ Upload Test Results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: test-results-${{ matrix.python-version }}
        path: |
          test-results.xml
          htmlcov/
          coverage.xml

  # ==========================================
  # ðŸ” CODE QUALITY & SECURITY
  # ==========================================
  
  code-quality:
    name: ðŸ” Code Quality Analysis
    runs-on: ubuntu-latest
    
    steps:
    - name: ðŸ“¥ Checkout Code
      uses: actions/checkout@v4
    
    - name: ðŸ Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: ðŸ“¦ Install Quality Tools
      run: |
        python -m pip install --upgrade pip
        pip install black flake8 isort mypy bandit safety pylint
        pip install -r requirements.txt
    
    - name: ðŸŽ¨ Check Code Formatting (Black)
      run: black --check --diff .
    
    - name: ðŸ“ Check Import Sorting (isort)
      run: isort --check-only --diff .
    
    - name: ðŸ” Lint Code (Flake8)
      run: flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
    
    - name: ðŸ” Extended Linting (Pylint)
      run: |
        pylint portfolio_return_calculator.py || true
        pylint streamlit_portfolio_app.py || true
    
    - name: ðŸ”’ Security Scan (Bandit)
      run: bandit -r . -f json -o bandit-report.json || true
    
    - name: ðŸ›¡ï¸ Dependency Security Check (Safety)
      run: safety check --json --output safety-report.json || true
    
    - name: ðŸ“Š Type Checking (MyPy)
      run: mypy . --ignore-missing-imports || true
    
    - name: ðŸ“‹ Upload Security Reports
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: security-reports
        path: |
          bandit-report.json
          safety-report.json

  # ==========================================
  # ðŸš€ PERFORMANCE TESTING
  # ==========================================
  
  performance:
    name: âš¡ Performance Benchmarks
    runs-on: ubuntu-latest
    
    steps:
    - name: ðŸ“¥ Checkout Code
      uses: actions/checkout@v4
    
    - name: ðŸ Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: ðŸ“¦ Install Dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest-benchmark memory-profiler
    
    - name: âš¡ Run Performance Tests
      run: |
        pytest test_portfolio_calculator.py::TestBenchmarks \
          --benchmark-only \
          --benchmark-json=benchmark-results.json
    
    - name: ðŸ“Š Upload Benchmark Results
      uses: actions/upload-artifact@v4
      with:
        name: benchmark-results
        path: benchmark-results.json
    
    - name: ðŸ“ˆ Performance Regression Check
      run: |
        # Add logic to compare with previous benchmarks
        echo "Performance benchmark completed"

  # ==========================================
  # ðŸ³ DOCKER BUILD & TEST
  # ==========================================
  
  docker:
    name: ðŸ³ Docker Build & Test
    runs-on: ubuntu-latest
    needs: [test, code-quality]
    
    steps:
    - name: ðŸ“¥ Checkout Code
      uses: actions/checkout@v4
    
    - name: ðŸ—ï¸ Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
    
    - name: ðŸ³ Build Docker Image
      run: |
        docker build -t ai-portfolio-calculator:test .
    
    - name: ðŸ§ª Test Docker Container
      run: |
        docker run --rm -d --name test-container -p 8501:8501 ai-portfolio-calculator:test
        sleep 30  # Wait for container to start
        
        # Health check
        curl -f http://localhost:8501/_stcore/health || exit 1
        
        # Cleanup
        docker stop test-container
    
    - name: ðŸ” Vulnerability Scan (Trivy)
      uses: aquasecurity/trivy-action@master
      with:
        image-ref: 'ai-portfolio-calculator:test'
        format: 'sarif'
        output: 'trivy-results.sarif'
    
    - name: ðŸ“‹ Upload Trivy Results
      uses: github/codeql-action/upload-sarif@v2
      if: always()
      with:
        sarif_file: 'trivy-results.sarif'

  # ==========================================
  # ðŸ“š DOCUMENTATION CHECKS
  # ==========================================
  
  documentation:
    name: ðŸ“š Documentation Quality
    runs-on: ubuntu-latest
    
    steps:
    - name: ðŸ“¥ Checkout Code
      uses: actions/checkout@v4
    
    - name: ðŸ” Check Documentation Links
      uses: gaurav-nelson/github-action-markdown-link-check@v1
      with:
        use-quiet-mode: 'yes'
        use-verbose-mode: 'yes'
        config-file: '.github/markdown-link-check-config.json'
    
    - name: ðŸ“ Spell Check
      uses: streetsidesoftware/cspell-action@v5
      with:
        files: "**/*.md"
        config: ".github/cspell.json"
    
    - name: ðŸ“‹ Documentation Coverage
      run: |
        # Check if all Python modules have docstrings
        python -c "
        import ast
        import glob
        
        def check_docstrings(filename):
            with open(filename, 'r') as f:
                tree = ast.parse(f.read())
            
            functions = [node for node in ast.walk(tree) if isinstance(node, ast.FunctionDef)]
            classes = [node for node in ast.walk(tree) if isinstance(node, ast.ClassDef)]
            
            missing_docs = []
            for func in functions:
                if not ast.get_docstring(func) and not func.name.startswith('_'):
                    missing_docs.append(f'Function: {func.name}')
            
            for cls in classes:
                if not ast.get_docstring(cls):
                    missing_docs.append(f'Class: {cls.name}')
            
            return missing_docs
        
        for py_file in glob.glob('*.py'):
            if py_file.startswith('test_'):
                continue
            missing = check_docstrings(py_file)
            if missing:
                print(f'{py_file}: Missing documentation for {len(missing)} items')
        "

  # ==========================================
  # ðŸŒŸ INTEGRATION TESTING
  # ==========================================
  
  integration:
    name: ðŸŒ Integration Tests
    runs-on: ubuntu-latest
    needs: [test]
    
    steps:
    - name: ðŸ“¥ Checkout Code
      uses: actions/checkout@v4
    
    - name: ðŸ Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: ðŸ“¦ Install Dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install selenium pytest-selenium
    
    - name: ðŸš€ Start Application
      run: |
        streamlit run streamlit_portfolio_app.py --server.port=8501 &
        echo $! > streamlit.pid
        sleep 30  # Wait for app to start
    
    - name: ðŸ§ª Run Integration Tests
      run: |
        pytest test_portfolio_calculator.py::TestIntegration -v
    
    - name: ðŸ›‘ Stop Application
      run: |
        if [ -f streamlit.pid ]; then
          kill $(cat streamlit.pid) || true
        fi

  # ==========================================
  # ðŸ“¦ BUILD & RELEASE
  # ==========================================
  
  build:
    name: ðŸ“¦ Build Package
    runs-on: ubuntu-latest
    needs: [test, code-quality, performance]
    if: github.event_name == 'release'
    
    steps:
    - name: ðŸ“¥ Checkout Code
      uses: actions/checkout@v4
    
    - name: ðŸ Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: ðŸ“¦ Install Build Dependencies
      run: |
        python -m pip install --upgrade pip setuptools wheel build twine
    
    - name: ðŸ—ï¸ Build Package
      run: |
        python -m build
    
    - name: ðŸ” Check Package
      run: |
        twine check dist/*
    
    - name: ðŸ“‹ Upload Build Artifacts
      uses: actions/upload-artifact@v4
      with:
        name: dist-packages
        path: dist/

  # ==========================================
  # ðŸš€ DEPLOYMENT
  # ==========================================
  
  deploy-staging:
    name: ðŸš€ Deploy to Staging
    runs-on: ubuntu-latest
    needs: [build]
    if: github.ref == 'refs/heads/develop'
    environment: staging
    
    steps:
    - name: ðŸ“¥ Checkout Code
      uses: actions/checkout@v4
    
    - name: ðŸ³ Deploy to Staging
      run: |
        echo "ðŸš€ Deploying to staging environment..."
        echo "Staging URL: https://ai-portfolio-staging.streamlit.app"
        # Add actual deployment commands here

  deploy-production:
    name: ðŸŒŸ Deploy to Production
    runs-on: ubuntu-latest
    needs: [build]
    if: github.event_name == 'release'
    environment: production
    
    steps:
    - name: ðŸ“¥ Checkout Code
      uses: actions/checkout@v4
    
    - name: ðŸŒŸ Deploy to Production
      run: |
        echo "ðŸŒŸ Deploying to production environment..."
        echo "Production URL: https://ai-portfolio-calculator.streamlit.app"
        # Add actual deployment commands here
    
    - name: ðŸ“¢ Create Deployment Notification
      uses: actions/github-script@v6
      with:
        script: |
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: 'ðŸš€ Successfully deployed to production! ðŸŽ‰'
          })

  # ==========================================
  # ðŸ“Š REPORTING & NOTIFICATIONS
  # ==========================================
  
  report:
    name: ðŸ“Š Generate Reports
    runs-on: ubuntu-latest
    needs: [test, code-quality, performance, integration]
    if: always()
    
    steps:
    - name: ðŸ“¥ Download All Artifacts
      uses: actions/download-artifact@v4
    
    - name: ðŸ“Š Generate Summary Report
      run: |
        echo "# ðŸ¤– AI Portfolio Calculator - CI/CD Report" > report.md
        echo "" >> report.md
        echo "## ðŸ“Š Test Results" >> report.md
        echo "- **Status**: ${{ needs.test.result }}" >> report.md
        echo "- **Code Quality**: ${{ needs.code-quality.result }}" >> report.md
        echo "- **Performance**: ${{ needs.performance.result }}" >> report.md
        echo "- **Integration**: ${{ needs.integration.result }}" >> report.md
        echo "" >> report.md
        echo "## ðŸ”§ Build Information" >> report.md
        echo "- **Commit**: ${{ github.sha }}" >> report.md
        echo "- **Branch**: ${{ github.ref }}" >> report.md
        echo "- **Author**: ${{ github.actor }}" >> report.md
        echo "- **Timestamp**: $(date)" >> report.md
    
    - name: ðŸ“‹ Upload Final Report
      uses: actions/upload-artifact@v4
      with:
        name: ci-cd-report
        path: report.md
    
    - name: ðŸ’¬ Slack Notification
      if: failure()
      uses: 8398a7/action-slack@v3
      with:
        status: failure
        channel: '#ci-alerts'
        webhook_url: ${{ secrets.SLACK_WEBHOOK }}
        text: "ðŸš¨ AI Portfolio Calculator CI/CD Pipeline Failed!"

# ==========================================
# ðŸ”§ WORKFLOW CONFIGURATION
# ==========================================

# Workflow concurrency control
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true 